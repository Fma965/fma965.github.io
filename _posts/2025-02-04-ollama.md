---
layout: post
title: "Ollama - Local Large Language Models (LLMs) + Open WebUI"
date: 2025-02-05 10:00:00 0000
categories: homelab services ai
tags: homelab ai ollama openweb-ui

---

## [Ollama](https://ollama.com/)
https://hub.docker.com/r/ollama/ollama

Ollama is an open-source tool that runs large language models (LLMs) directly on a local machine. This makes it particularly appealing to AI developers, researchers, and businesses concerned with data control and privacy.

By running models locally, you maintain full data ownership and avoid the potential security risks associated with cloud storage. Offline AI tools like Ollama also help reduce latency and reliance on external servers, making them faster and more reliable.

I use Ollama to run various LLM's, my current preferred LLM's include llama, deepseek and llava.


## [Open WebUI](https://openwebui.com/)
https://ghcr.io/open-webui/open-webui

Open WebUI is an extensible, self-hosted AI interface that adapts to your workflow, all while operating entirely offline.

This is simply a web interface to use with Ollama, OpenAI etc.